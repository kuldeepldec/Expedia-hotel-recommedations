import pandas as pd
import numpy as np
import operator
from sklearn.decomposition import PCA
from sklearn.base import TransformerMixin



class DataFrameImputer(TransformerMixin):

    def __init__(self):
        """Impute missing values.

        Columns of dtype object are imputed with the most frequent value 
        in column.

        Columns of other types are imputed with mean of column.

        """
    def fit(self, X, y=None):

        self.fill = pd.Series([X[c].value_counts().index[0]
            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],
            index=X.columns)

        return self

    def transform(self, X, y=None):
        return X.fillna(self.fill)


''' remove unwanted columns in training data generate
and generating missing value'''
def training_data(df):
         
    df=df.drop(df.columns[[0,8,9,10,11,12,13,14,15,19]], axis=1)
    #removing data that is not important
    df = DataFrameImputer().fit_transform(df)
    
  
    return df

''' remove unwanted columns in testing data generate
and generating missing value'''    
def testing_data(df):
    #removing data that is not important
    df=df.drop(df.columns[[0,1,9,10,11,12,13,14,15,16]], axis=1)
    df = DataFrameImputer().fit_transform(df)
    df['id'] = range(1, len(df) + 1)
    return df
        
        
  
def make_key(items):
    return "_".join([str(i) for i in items])

# generating exact match for hotel clusters and destination
def generate_exact_matches(row, match_cols):
    index = tuple([row[t] for t in match_cols])
    try:
        group = groups.get_group(index)
    except Exception:
        return []
    clus = list(set(group.hotel_cluster))
    return clus

# generating exact match for hotel clusters and destination on test data
def f5(seq, idfun=None): 
    if idfun is None:
        def idfun(x): return x
    seen = {}
    result = []
    for item in seq:
        marker = idfun(item)
        if marker in seen: continue
        seen[marker] = 1
        result.append(item)
    return result


if __name__=="__main__":
    #reading destination file
    destinations = pd.read_csv("destinations.csv")
    #reading train data 
    train = pd.read_csv("train1.csv")
    #reading test data 
    test=pd.read_csv("test.csv")
    # removing umwanted columns and filling missing value in test and train
    ct=training_data(train)
    test_t=testing_data(test)
    
   
    
  
    #using pca to generate new data of destination 
    pca = PCA(n_components=3)
    dest_small = pca.fit_transform(destinations[["d{0}".format(i + 1) for i in range(149)]])
    dest_small = pd.DataFrame(dest_small)
    dest_small["srch_destination_id"] = destinations["srch_destination_id"]
    #joining destination data with main data
    ct = ct.join(dest_small, on="srch_destination_id", how='left', rsuffix="dest")
    test_t=test_t.join(dest_small,on="srch_destination_id", how='left', rsuffix="dest")
    
    # removing na in train and test data
    ct=ct.dropna()
        
    
    
    
    
    #renaming all the columns in train and test data
    ct.columns=['site_name', 'posa_continent', 'user_location_country','user_location_region'
,'user_location_city','orig_destination_distance','user_id','srch_destination_id','srch_destination_type_id','is_booking','hotel_continent','hotel_country','hotel_market','hotel_cluster', 'dest1','dest2', 'dest3','srch_destination']


    test_t.columns=['site_name', 'posa_continent', 'user_location_country','user_location_region'
,'user_location_city','orig_destination_distance','user_id','srch_destination_id','srch_destination_type_id','hotel_continent','hotel_country','hotel_market', 'dest1','dest2', 'dest3','srch_destination','id']

    #Selecting features from the search destination and matching with hotel clusters
    
    
    match_cols = ['dest1','dest2','dest3','srch_destination']
    
    cluster_cols = match_cols + ['hotel_cluster']
    groups = ct.groupby(cluster_cols)
    
    
    # test data has only booking so giving 100% weightage to book data and 10% weightage
    # to click data
    top_clusters = {}
    for name, group in groups:
        clicks = len(group.is_booking[group.is_booking == False])
        bookings = len(group.is_booking[group.is_booking == True])
        score = bookings + .10 * clicks
        clus_name = make_key(name[:len(match_cols)])
        if clus_name not in top_clusters:
            top_clusters[clus_name] = {}
        top_clusters[clus_name][name[-1]] = score

    # finding top cluster data
    cluster_dict = {}
    for n in top_clusters:
        tc = top_clusters[n]
        top = [l[0] for l in sorted(tc.items(), key=operator.itemgetter(1), reverse=True)[:5]]
        cluster_dict[n] = top
        
    #predicting cluster data on test data with destinations
    preds = []
    for index, row in test_t.iterrows():
        key = make_key([row[m] for m in match_cols])
        if key in cluster_dict:
            preds.append(cluster_dict[key])
        else:
            preds.append([])

    #finding top hotel clusters
    most_common_clusters = list(train.hotel_cluster.value_counts().head().index)
    # making new data from user location,region,city and hotel location
    match_cols = ['user_location_country', 'user_location_region', 'user_location_city', 'hotel_market','hotel_continent']
    # grouping all the above value
    groups = train.groupby(match_cols)

    

    # matching value of the cluster on test data
    exact_matches = []
    for i in range(test_t.shape[0]):
        exact_matches.append(generate_exact_matches(test_t.iloc[i], match_cols))

    full_preds = [f5(exact_matches[p] + preds[p] + most_common_clusters)[:5] for p in range(len(preds))]


    #writing value of hotel cluster in csv file by matching id 

    write_p = [" ".join([str(l) for l in p]) for p in full_preds]
    
    # making a dictionary of id and hotel cluster
    write_frame = ["{0},{1}".format(test_t["id"].iloc[i], write_p[i]) for i in range(len(full_preds))]

    write_frame = ["id","hotel_clusters"] + write_frame
    
    #writing id and hotel cluster  
    with open("predictions.csv", "w+") as f:
        f.write("\n".join(write_frame))
    











    




    